---
title: "Project 1"
author: "Braden Anderson and Luke Stodgel"
date: "10/23/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r echo=FALSE}
# Introduction
# First we explored how many breweries are in each state. For this, we decided to make a heat map. The darker states represent states with more breweries and the lighter states represent states with fewer breweries. The top 5 states with the most breweries are Colorado, California, Michigan, Oregon, and Texas.

# Next we will go over how we handled missing data. We saw that there was missing data in the Style, ABV and IBU columns. For the Style column there were five beers without data. Two beers were not actually beers so we removed those rows. For the three remaining beers we filled in their Style using info we found online. For ABV we found that 60 beers were missing information. For 51 of the 60, we filled in the data using info we found on the internet. The nine beers that we couldn't find online were filled in using the maximum ABV for the associated beer style. For IBU we found 1003 beers missing data. All values were imputed using the mean IBU for the associated beer style. If no other beers within that style had IBU information available, the global mean IBU rating was used.

# Next we looked the median ABV and IBU for each state. We provided graphs in our powerpoint showing the median ABV for each state and the median IBU for each state.

# Now for the summary statistics of ABV, the beer with the lowest ABV had .1%, Q1 was 5.0%, the median was 5.6%, the mean was 5.977%, Q3 was 6.7%, and the beer with the highest ABV was 12.8%. As shown in the graph in our powerpoint, the data is shaped like a long-tailed distribution but it is fairly symmetrical around 6% ABV.

# Next we will talk about the relationship between IBU and ABV. We plotted all of the beers based on their IBU and ABV and determined that there was a trend. The trend we found was that as IBU increased, so did ABV. Still, there is a larger variation in IBU among beers with higher ABV.

# We ran two KNN tests: one on IPA style beers and another on Ale style beers. When categorizing IPAs, our best accuracy was achieved using k=4 and the accuracy was 91.69%. For Ales, our best accuracy was achieved using k=1 and the accuracy was 66.635%. We concluded that IBU and ABV are more strongly related for IPA style beers than for Ales.

# Finally for some extra analysis we looked at potential expansion opportunities around the US. We created a map containing the locations of every brewery in our data set. If you look in the powerpoint and see the map, you can see that there are some states that don't have many breweries in them, if any. Our proposal is that if the conditions are right, and it is appropriate to do so, we could expand our business to these places in the country.

# Thank you very much for your time.
```
## Data Imports

```{r echo=FALSE}

library(naniar)
library(magrittr)
library(ggplot2)
library(e1071)
library(dplyr)
library(caret)
library(class)
library(tidyverse)
library(maps)
library(mapproj)

# Read in the beer dataset.
beer_df = read.csv("./Project1Files/Beers.csv")

# Read in the brewery dataset.
brewery_df = read.csv("./Project1Files/Breweries.csv")

# Take a look at the first few rows of the brewery dataset.
head(brewery_df)
```

## How many breweries are present in each state?

```{r echo=FALSE}

# Count the number of breweries per state.
breweries_per_state <- brewery_df %>% group_by(State) %>% summarize(count = n())

# Rename the count column, and convert to a dataframe.
breweries_per_state <- as.data.frame(rename(breweries_per_state, Breweries=count))

# Trim unnecessary white space from abbreviations in the "State" column.
breweries_per_state$State <- trimws(breweries_per_state$State)

# View the count of breweries in the first few states (alphabetically).
head(breweries_per_state)
```

## How many breweries are present in each state (set up for visualization).

```{r echo=FALSE}

# Create a dataframe of state abbreviations and state full names.
state_name_lookup <- data.frame(State = state.abb, name=state.name)

# Merging to add a column with full state names to breweries_per_state.
breweries_per_state <- merge(state_name_lookup, breweries_per_state)

# Adding "region" column name for easy merging with location data.
breweries_per_state$region <- tolower(breweries_per_state$name)

# Get the latitude and longitude coordinates for each states boarder.
states <- map_data("state")

# Merge the location data with the count data.
# This will merge on the shared "region" column.
brewery_map <- merge(states, breweries_per_state)

# Order the long, lat according to the "order" column,
# this makes sure the state boarders get drawn correctly.
brewery_map <- brewery_map[order(brewery_map$order),]

##########################################################################################################################
############# This section is just to set up for annotating the top five brewery containing states on the map ############
##########################################################################################################################

# Create a dataframe sorted by number of breweries (state with the most breweries on top).
sorted_num_breweries <- breweries_per_state[order(breweries_per_state$Breweries,decreasing = TRUE),]

# Use head to create a dataframe with just the top 5 rows.
# (Contains the states with the top 5 most breweries in them).
top_5 <- head(sorted_num_breweries, n=5)

# Merge our top 5 states with the location data.
top_5_states <- merge(states, top_5)

# Find coordinates of the center of each state in our top 5.
top_5_state_location <- top_5_states %>% group_by(region) %>% summarize(max_long=max(long),
                                                                        min_long=min(long),
                                                                        center_long=min(long) + (max(long) - min(long))/2,
                                                                        max_lat=max(lat),
                                                                        min_lat=min(lat),
                                                                        center_lat=min(lat) + (max(lat)-min(lat))/2,
                                                                        brewery_count=max(Breweries),
                                                                        group=max(group))

# Convert our data on the top 5 brewery containing states to a dataframe.
top_5_df <- as.data.frame(top_5_state_location)

# Special adjustment for michigan, because the lakes get in the way if you use the center.
# (Scooting the location over to the right of the lakes).
top_5_df[top_5_df["region"] == "michigan", "center_long"] <- top_5_df[top_5_df["region"] == "michigan", "center_long"] + 2

# Create a dataframe with the annotation locations (lat, long), as well as the annotation text.
annot <- data.frame(x=top_5_df$center_long,
                    y=top_5_df$center_lat,
                    text=as.character(top_5_df$brewery_count),
                    group=top_5_df$group)


##########################################################################################################################
############################################## End annotation setup section ##############################################
##########################################################################################################################

```

## Question 1: Visualize breweries by state

```{r echo=FALSE, fig.width=10,fig.height=8}

# Plot the heat map, with annotation for the top 5 states.
ggplot(brewery_map, aes(x=long,y=lat, group=group)) +
  geom_polygon(aes(fill=Breweries)) +
  geom_path() + 
  scale_fill_gradientn(colours=rev(heat.colors(12)),na.value="grey90") + 
  geom_text(data=annot, aes(x=x, y=y, label=text)) +
  ggtitle("Breweries by State")+
  xlab("longitude") + 
  ylab("latitude") +
coord_map()


# The number of breweries for each state are shown on the heatmap below.
```
## Question 2: Merge beer data with the breweries data

```{r echo=FALSE}

# Merge the beer and brewery data on beer_df.Brewery_id = brewery_df.Brew_ID
combined_df <- merge(x=beer_df,
                     y=brewery_df,
                     by.x="Brewery_id",
                     by.y="Brew_ID")

# Rename the "Name.x" and "Name.y" columns generated by the merge
# to more informative names (Beer_Name and Brewery_Name).
combined_df <- rename(combined_df,
                      Beer_Name=Name.x,
                      Brewery_Name=Name.y)

# View the first few rows of the combined dataset.
head(combined_df)


```

## Question 3: Address the missing values.

```{r echo=FALSE}

# visualize where the missing values are
gg_miss_var(combined_df)



# The missing values were handled by a combination of removing observations not relevant to a beer analysis (non-beer items),
# finding correct values for missing information (looking up online), and imputing with best estimates (average by group). A 
# detailed analysis of each decision is provided below.


```

```{r echo=FALSE}

# Display the beers that are missing a "style". (they aren't actually NaNs but they are blank).
# Also note that 3 of the 5 beers that are missing a "style", are also missing
# the "ABV" and "IBU" information. We don't have much info on these three beers at all. 
combined_df[combined_df[,"Style"]== "", ]

#### Investigating the "beers" with missing style
#
#
# CAN'D AID Foundation: This is not a beer. This was a partnership with Oskar brewing company to 
# distribute cans of drinking water to people in need during the COVID-19 pandemic. This was a very
# nice thing to do, but I do not believe it is relavent to a beer and brewery data analysis, and as such
# this observation will be dropped.
#
# The CROWLER: This is also not a beer. The "CROWLER" is a 32oz can than is intended to be a replacement
# for a growler. So yes, it can contain beer, but is not a specific beer by itself. As such, I believe we
# can safely remove this observation without losing any beer information.

#
# Special Release: There is some uncertainty with this observation, as this could possibly be one of several 
# special release beers. However I believe it is reasonable to impute these missing values with the information
# contained at this link: https://www.beeradvocate.com/beer/profile/29745/131821/?ba=dseanv
# sl_style = "American Amber / Red Ale"

#
# OktoberFiesta: https://untappd.com/b/freetail-brewing-co-oktoberfiesta/79567
# oct_fiesta_style = "MÃ¤rzen / Oktoberfest"

#
# Kilt lifter scottish style ale.... its right in the name (Scottish Style), also, see link below.
# https://www.fourpeaks.com/beer/year-round/kilt-lifter/
# kl_style = "Scottish Style"  
  
```


```{r echo=FALSE}

# Based on the above analysis, the following decisions were made:
#
# 1) Remove the crowler and can'd aid observations
# 2) Impute the missing style for the special release, oktoberfiesta and kilt lifer observations with the following:
sl_style = "American Amber / Red Ale"
oct_fiesta_style = "MÃ¤rzen / Oktoberfest"
kl_style = "Scottish Style"

# Fill in missing style information for the Oktober beer.
combined_df[combined_df["Beer_ID"] == 2527, "Style"] = oct_fiesta_style

# Fill in missing style information for the Kilt beer.
combined_df[combined_df["Beer_ID"] == 1635, "Style"] = kl_style

# Fill in missing style information for the special edition beer.
combined_df[combined_df["Beer_ID"] == 2210, "Style"] = sl_style

# Setup filters to remove crowler and cand_aid observations.
crowler_filter <- combined_df["Beer_ID"] == 1796
cand_aid_filter <- combined_df["Beer_ID"] == 1790
filters <- crowler_filter | cand_aid_filter

# Verify our filters will remove exactly two items.
sum(filters)

# Remove the crowler and cand aid observations.
combined_df <- combined_df[!filters,]

# Verify we no longer have any observations with missing style.
combined_df[combined_df[,"Style"]== "", ]

```


```{r echo=FALSE}

# Display the number of missing values in the ABV column.
sum(is.na(combined_df[,"ABV"]))

# We currently have 60 beers missing alcohol content information.
```


```{r echo=FALSE}

# Create a dataframe containing the rows where we are missing the ABV value
missing_abv_df <- combined_df[is.na(combined_df[,"ABV"]), ]

# Save the observations with missing ABV values to a csv, so we can manually 
# search the internet and fill in any info we find. 
write.csv(missing_abv_df, "./beers_with_missing_abv.csv")

```


```{r echo=FALSE}

# Read in dataset that contains values we can fill in for missing ABV values (from internet searches).
abv_fillin_df = read.csv("./Project1Files/beers_fillin_abv.csv")

head(abv_fillin_df)

```




```{r echo=FALSE}

# Create filters to subset just the rows where we are missing the alcohol information
# AND where the name is in the list of names we searched the internet for the correct info on.
fillin_filter <- combined_df$Beer_Name %in% abv_fillin_df$Beer_Name
missing_filter <- is.na(combined_df$ABV)
miss_and_found_filter <- fillin_filter & missing_filter

# Impute the missing values with the ones we found.
combined_df[miss_and_found_filter, "ABV"] <- abv_fillin_df$ABV

# Check how many beers are now missing alcohol content.
# Ten, not bad! we started with 60!
sum(is.na(combined_df$ABV))

```

```{r echo=FALSE}

# Special Release was one we looked up before, this should have been filled in earlier.
# The rest of the beers were very difficult to find any info on (many are special year brews)!
combined_df[is.na(combined_df$ABV),]

# Take care of imputing the special release beer at 7% alcohol.
combined_df[combined_df["Beer_ID"]==2210, "ABV"] = 0.07

# Take one more look at the beers with missing alcohol content, down to 9 of them!
combined_df[is.na(combined_df$ABV),]

```


```{r echo=FALSE}

# To take care of these last 9 beers with missing alcohol content, we will perform the following:
#
# Based on the domain knowledge that alcohol content of a beer is related to its style, we could compute the average
# alcohol content for each style and impute accordingly. However, there may be some higher risk associated with underestimating
# a beers alcohol content. If the alcohol content is underestimated, someone may over-drink and have negative consequences. 
# Therefore, we can take the conservative estimate of computing the maximum alcohol content per beer style, and use these
# values to impute the 9 beers with missing alcohol content information.

# Compute the maximum alcohol content for each beer style.
max_alch_by_style <- combined_df[!is.na(combined_df[,"ABV"]),] %>% group_by(Style) %>% summarize(max_alch=max(ABV))

# Convert to a dataframe.
max_alch_by_style <- as.data.frame(max_alch_by_style)

# Display the maximum alcohol content for the first few beer styles.
head(max_alch_by_style)

```


```{r echo=FALSE}

# Grab the beer ids for the remaining beers missing alcohol content info.
beers_missing_abv <- combined_df[is.na(combined_df$ABV), "Beer_ID"]

# For each beer_id in the list of beer_ids where a beer is missing ABV information.
for(beer_id in beers_missing_abv){
  
  # Grab the style of that beer.
  style <- combined_df[combined_df["Beer_ID"] == beer_id, "Style"]
  
  # Use our style --> max_alch map to get the max_alch for this beer style.
  max_alch <- max_alch_by_style[max_alch_by_style[,"Style"] == style, "max_alch"]
  
  # Update the ABV for this beer to the max alch for the associated beer style
  combined_df[combined_df["Beer_ID"] == beer_id, "ABV"] <- max_alch
  
}

# Verify that we now have ZERO missing values in the ABV column.
sum(is.na(combined_df$ABV))

```



```{r echo=FALSE}

# Check how many missing values we have in the IBU column.
sum(is.na(combined_df$IBU))

```



```{r echo=FALSE}

# Following a similar template as established above, we will now calculate the average IBU rating for each 
# beer style, and then will impute missing IBU values using the mean IBU for the associated style.
#
#

# Calculate mean IBU for each beer style.
mean_ibu_by_style <- combined_df[!is.na(combined_df[,"IBU"]),] %>% group_by(Style) %>% summarize(avg_ibu=mean(IBU))

# Convert to a Dataframe.
mean_ibu_by_style <- as.data.frame(mean_ibu_by_style)

# Take a look at the first few rows
head(mean_ibu_by_style)

```



```{r echo=FALSE}

# Grab the beer ids for the beers missing IBU information.
beers_missing_ibu <- combined_df[is.na(combined_df$IBU), "Beer_ID"]

# Global IBU mean for last resort fill in (see if statement inside for loop for more info).
global_mean_IBU <- mean(combined_df[!is.na(combined_df$IBU),"IBU"])

# For each beer_id in the list of beer_ids corresponding to beers missing IBU information.
for(beer_id in beers_missing_ibu){
  
  # Grab the style of that beer.
  style <- combined_df[combined_df["Beer_ID"] == beer_id, "Style"]
  
  # Use our style --> average_IBU map to get the average IBU rating for this beer style.
  average_ibu <- mean_ibu_by_style[mean_ibu_by_style[,"Style"] == style, "avg_ibu"]
  
  # Last resort, if average_ibu is length zero, which means there is no other beers with this style
  # to take an IBU average over.... in this case, fill in with the global average IBU rating.
  # else, fill in with the mean within the associated style.
  if(length(average_ibu) == 0){
    
    combined_df[combined_df["Beer_ID"] == beer_id, "IBU"] <- global_mean_IBU
    
  }else{ # else, fill in with the average IBU for this particular beer style.
  
    combined_df[combined_df["Beer_ID"] == beer_id, "IBU"] <- average_ibu   
    
  }
  
}

# Verify that we now have ZERO missing values in the IBU column.
sum(is.na(combined_df$IBU))

```

```{r echo=FALSE}

# visualize the missing values one more time, verify there are now zero missing values in all columns.
gg_miss_var(combined_df)

```

## Question 4: Compute the median alcohol content and IBUs for each state.
## Plot a bar chart to compare. 

```{r echo=FALSE}

# Compute the mean ABV and IBU for beers in each state.
medians_by_state <- combined_df %>% group_by(State) %>% summarize(median_abv=median(ABV),
                                                                  median_ibu=median(IBU))

# Convert the IBU and ABV by state information created above to a data frame.
medians_by_state <- as.data.frame(medians_by_state)


# Take a look at the first few rows.
head(medians_by_state)

```


```{r echo=FALSE}

# Barplot of median alcohol content by state.
ggplot(data=medians_by_state) + 
  geom_bar(stat='identity', mapping=aes(x=reorder(State, median_abv), y=median_abv), fill="aquamarine4", color="navy") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + 
  xlab("State") + 
  ylab("Median Alcohol Content of Beers") + 
  ggtitle("Median Alcohol Content in Beers by State")

```


```{r echo=FALSE}

# Barplot of median IBU by state.
ggplot(data=medians_by_state) + 
  geom_bar(stat='identity', mapping=aes(x=reorder(State, median_ibu), y=median_ibu), fill="deeppink3", color="navy") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + 
  xlab("State") + 
  ylab("Median IBU Rating of Beers") + 
  ggtitle("Median IBU Rating of Beers by State")

```

## Question 5: Which state has the maximum alcoholic (ABV) beer? 
##             Which state has the most bitter (IBU) beer?

```{r}

# Which state has the maximum alcoholic (ABV) beer?
# Step 1 find highest ABV
maxABV <- max(combined_df$ABV, na.rm = TRUE)

# Step 2 get Brewery_ID using max ABV
maxABVBreweryID = combined_df %>% filter(ABV == maxABV) %>% select(Brewery_id)
maxABVBreweryID = as.integer(maxABVBreweryID) # 52 - Upslope Brewing Company. What a coincidence my brother's old room mate used to work here when they lived in Boudler, CO.

# Step 3 find state using maxABVBreweryID
combined_df %>% filter(Brewery_id == maxABVBreweryID) %>% select(State)
#
# It's Colorado (12.8% ABV) - Lee Hill Series Vol. 5 - Belgian Style Quadrupel Ale - 
# Upslope Brewing Company, Boulder, CO.


# Step 1 find highest IBU
maxIBU <- max(combined_df$IBU, na.rm = TRUE)

# Step 2 get Brewery_id using max IBU
maxIBUBreweryID = combined_df %>% filter(IBU == maxIBU) %>% select(Brewery_id)
maxIBUBreweryID = as.integer(maxIBUBreweryID)

# Step 3 find state using maxIBUBreweryID 
combined_df %>% filter(Brewery_id == maxIBUBreweryID) %>% select(State)
#
# It's Oregon (138 IBU) - Bitter Bitch Imperial IPA - American Double / Imperial IPA 
# Astoria Brewing Company, Astoria, OR.
```

## Question 6: Comment on the summary statistics and distribution 
##             of the ABV variable.

```{r echo = FALSE}

summary(combined_df$ABV)
# The beer with the lowest ABV has .1%, Q1 has 5%, the median is 5.6%, Q3 has 6.7%, the mean percentage ABV is 5.98, and the highest ABV is 12.8%
# There is definitely a large difference in ABV between the min and the max values.
# Below is a plot of numBeers categorized by ABV. By plotting all of the beers with respect to their ABV in a bar chart, we can see that this data is right skewed. A large portion of the beers are within the 4.5-6.25% ABV range.

combined_df %>% 
  ggplot(aes(x = ABV)) + 
  geom_histogram() + 
  ggtitle("Num Beers at each ABV")
# Histogram plotting number of beers at their respective ABV.

```

## Question 7: Is there an apparent relationship between the bitterness of the 
##             beer and its alcoholic content? Draw a scatter plot.  

##             Make your best judgment of a relationship and 
##             EXPLAIN your answer.

```{r echo = FALSE}

combined_df %>% 
  select(IBU, ABV) %>% 
  ggplot(aes(x = ABV, y = IBU)) + 
  geom_point() +
  geom_smooth(method='lm') +
  ggtitle("IBU Vs. ABV")
# According to the chart, it looks like there is a relationship between IBU and ABV. The trend looks like as ABV increases, so does IBU. 
# Some outliers do exist; For example the beer with the highest ABV does not have the highest IBU, and beer with the lowest ABV does not have the lowest IBU. 
# It looks like the largest cluster of beers in this chart is within the 3.75%-6.25% ABV and 12.5-50 IBU range.

```

## Question 8: Budweiser would also like to investigate the difference with 
##             respect to IBU and ABV between IPAs (India Pale Ales) and other 
##             types of Ale (any beer with “Ale” in its name other than IPA).

##             You decide to use KNN classification to investigate this 
##             relationship.  Provide statistical evidence one way or the other. 

##             You can of course assume your audience is comfortable with 
##             percentages … KNN is very easy to understand conceptually.

##             In addition, while you have decided to use KNN to investigate 
##             this relationship (KNN is required) you may also feel free to 
##             supplement your response to this question with any other methods 
##             or techniques you have learned.  Creativity and alternative 
##             solutions are always encouraged. 

```{r echo = FALSE}

##################
# Knn.cv for IPAs#
##################
# Testing to see if knn.cv can correctly identify the Style of beer based on ABV and IBU

# extract only beers with style "IPA"
beerIPA = combined_df %>% filter(grepl("IPA",Style))
beerIPA = droplevels(beerIPA,exclude = !beerIPA)

set.seed(1)
iterations = 100
numks = 50

masterAccIPA = matrix(nrow = iterations, ncol = numks)
masterSensitivityIPA = matrix(nrow=iterations, ncol=numks)
masterSpecificityIPA <- matrix(nrow=iterations, ncol=numks)

for(j in 1:iterations)
{
  
  for(i in 1:numks)
  {
    CM = confusionMatrix(table(beerIPA[,6],knn.cv(beerIPA[,c(4,5)],beerIPA[,6],k = i)))
    masterAccIPA[j,i] = CM$overall[1]
    masterSensitivityIPA[j, i] <- mean(CM$byClass[,"Sensitivity"], na.rm = TRUE)
    masterSpecificityIPA[j, i] <- mean(CM$byClass[,"Specificity"], na.rm = TRUE)
  }
  
}

# use the 50 accuracies from each test in the for-loop  above and store it in MeanAccIPA
MeanAccIPA = colMeans(masterAccIPA)
MeanSenseIPA <- colMeans(masterSensitivityIPA)
MeanSpecIPA <- colMeans(masterSpecificityIPA)

# plot each accuracy at each K value
plot(seq(1,numks,1),MeanAccIPA)

# Find the k value (num neighbors) that maximized average accuracy, average sensitivity and average specificity
maxAccIPA <- which.max(MeanAccIPA)
maxSenseIPA <- which.max(MeanSenseIPA)
maxSpecIPA <- which.max(MeanSpecIPA)


confusionMatrix(table(beerIPA[,6],knn.cv(beerIPA[,c(4,5)],beerIPA[,6],k = 1))) # accuracy = 0.9159
confusionMatrix(table(beerIPA[,6],knn.cv(beerIPA[,c(4,5)],beerIPA[,6],k = 4))) # accuracy = 0.9177
confusionMatrix(table(beerIPA[,6],knn.cv(beerIPA[,c(4,5)],beerIPA[,6],k = 10))) # accuracy = 0.8844
confusionMatrix(table(beerIPA[,6],knn.cv(beerIPA[,c(4,5)],beerIPA[,6],k = 20))) # accuracy = 0.8336


##################
# Knn.cv for Ales#
##################

# extract only beers with style "Ale" and not with "IPA"
beerAle = combined_df %>% filter(grepl("Ale",Style) & !grepl("IPA",Style))
beerAle = droplevels(beerAle,exclude = !beerAle)

set.seed(1)
iterations = 100
numks = 50

masterAccAle = matrix(nrow = iterations, ncol = numks)
masterSensitivityAle = matrix(nrow=iterations, ncol=numks)
masterSpecificityAle <- matrix(nrow=iterations, ncol=numks)

for(j in 1:iterations)
{
  
  for(i in 1:numks)
  {
    CM = confusionMatrix(table(beerAle[,6],knn.cv(beerAle[,c(4,5)],beerAle[,6],k = i)))
    masterAccAle[j,i] = CM$overall[1]
    masterSensitivityAle[j, i] <- mean(CM$byClass[,"Sensitivity"], na.rm = TRUE)
    masterSpecificityAle[j, i] <- mean(CM$byClass[,"Specificity"], na.rm = TRUE)
    
  }
  
}

# use the 50 accuracies from each test in the for-loop  above and store it in MeanAccAle
MeanAccAle = colMeans(masterAccAle)
MeanSenseAle <- colMeans(masterSensitivityAle)
MeanSpecAle <- colMeans(masterSpecificityAle)

# plot each accuracy at each K value
plot(seq(1,numks,1),MeanAccAle)

maxAccAle <- which.max(MeanAccAle)
maxSenseAle <- which.max(MeanSenseAle)
maxSpecAle <- which.max(MeanSpecAle)

confusionMatrix(table(beerAle[,6],knn.cv(beerAle[,c(4,5)],beerAle[,6],k = 1))) # accuracy = 0.6691
confusionMatrix(table(beerAle[,6],knn.cv(beerAle[,c(4,5)],beerAle[,6],k = 5))) # accuracy = 0.6525
confusionMatrix(table(beerAle[,6],knn.cv(beerAle[,c(4,5)],beerAle[,6],k = 10))) # accuracy = 0.6245
confusionMatrix(table(beerAle[,6],knn.cv(beerAle[,c(4,5)],beerAle[,6],k = 20))) # accuracy = 0.5902

#The best accuracy for IPAs was 91.77% and for Ales it was 66.91%. It is understandable that the Ales did not classify as well as the IPAs considering there is almost twice the amount of data for Ales and also there are 28 different Styles of Ales. IPAs only had 5 unique Styles. K=4 achieved the highest accuracy for IPAs and k=1 provided the best accuracy for Ales.

#shows 28 different Ales
beerAle %>% count(Style)
#shows 5 different IPAs
beerIPA %>% count(Style)

#######################
# NB test on same data#
#######################
#IPAs first

iterations = 95

masterAccNBIPA = matrix(nrow = iterations)
masterSensitivityNBIPA = matrix(nrow=iterations)
masterSpecificityNBIPA <- matrix(nrow=iterations)

for(j in 1:iterations)
{
  set.seed(j)
  trainIndicies = sample(seq(1:length(beerIPA$Style)),round(.7*length(beerIPA$Style)))
  trainIPA = beerIPA[trainIndicies,]
  testIPA = beerIPA[-trainIndicies,]
  
  model = naiveBayes(trainIPA[,c(4,5)],trainIPA$Style, laplace = 1)
  table(predict(model,testIPA[,c(4,5)]),testIPA$Style)
  CM = confusionMatrix(table(predict(model,testIPA[,c(4,5)]),testIPA$Style))
  
  masterAccNBIPA[j] = CM$overall[1]
  masterSensitivityNBIPA[j] <- mean(CM$byClass[,"Sensitivity"], na.rm = TRUE)
  masterSpecificityNBIPA[j] <- mean(CM$byClass[,"Specificity"], na.rm = TRUE)
}

MeanAccNBIPA = colMeans(masterAccNBIPA)
MeanSenseAle <- colMeans(masterSensitivityNBIPA)
MeanSpecAle <- colMeans(masterSpecificityNBIPA)

MeanAccNBIPA
#Mean accuracy here is 89.8% using the Naive Bayes method.

###############
# Testing Ales#
###############
#Beers that only appear once are causing issues within the model. Since this is extra work I will abandon this part. - Luke 

#beerAle = beerAle[grep("Wheat Ale",beerAle$Style,invert = TRUE), ]
#beerAle = beerAle[grep("Flanders Red Ale",beerAle$Style,invert = TRUE),]
#beerAle = beerAle[grep("Old Ale",beerAle$Style,invert = TRUE), ]

#iterations = 10

#masterAccNBAle = matrix(nrow = iterations)

#for(j in 1:iterations)
#{
#  set.seed(j)
#  trainIndicies = sample(seq(1:length(beerAle$Style)),round(.7*length(beerAle$Style)))
#  trainAle = beerAle[trainIndicies,]
#  testAle = beerAle[-trainIndicies,]
  
#  model = naiveBayes(trainAle[,c(4,5)],trainAle$Style, laplace = 1)
#  table(predict(model,testAle[,c(4,5)]),testAle$Style)
#  CM = confusionMatrix(table(predict(model,testAle[,c(4,5)]),testAle$Style))
  
#  masterAccNBAle[j] = CM$overall[1]
#}

#MeanAccNBAle = colMeans(masterAccNBAle)
#MeanAccNBAle

```

```{r echo = FALSE}

#
# Function for plotting KNN Metrics versus the number of neighbors used by the model.
#
knn_metric_plotter <- function(num_neighbors, mean_metric, best_k, metric_name="Accuracy", v_offset_multiplier=0.01, 
                               h_shift=0.25, txt_color="red", best_value_marker_shape=8, best_value_marker_color="red",
                               best_value_marker_size=5, annot_round_digits=5, beer_style="IPA") {
  
  
  df <- data.frame(num_neighbors_k=seq(1,num_neighbors,1), mean_metric_value=mean_metric)
  
  best_df <- df[df["num_neighbors_k"] == best_k,]
  
  max_metric_pct <- best_df[, "mean_metric_value"]
  
  best_df$y_txt <- max_metric_pct + (v_offset_multiplier * max_metric_pct)
  best_df$x_txt <- best_k + h_shift
  best_df$txt <- paste0(as.character(round(max_metric_pct, annot_round_digits)), ", k = ", as.character(best_k))
  

  p <- ggplot(data=df) + 
      geom_point(aes(x=num_neighbors_k, y=mean_metric_value)) +
      geom_point(data=best_df, aes(x=num_neighbors_k, y=mean_metric_value), color=txt_color) +
      geom_point(data=best_df, aes(x=num_neighbors_k, y=mean_metric_value), shape=best_value_marker_shape, 
                 size=best_value_marker_size, color=best_value_marker_color) +
      geom_text(data=best_df, aes(x=x_txt, y=y_txt, label=txt), color=best_value_marker_color) + 
      theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + 
      xlab("Number of neighbors used in KNN") + 
      ylab(paste0("Average Test ", metric_name)) + 
      ggtitle(paste0("Avg Test ", metric_name, " vs Number of Neighbors (KNN), For ", beer_style," Style Beers"))
  
  
  return(p)
  
}

```

```{r echo = FALSE}

# KNN ACCURACY PLOT - IPAS ONLY
knn_metric_plotter(num_neighbors=50, mean_metric=MeanAccIPA, best_k=maxAccIPA)

```




```{r echo = FALSE}

# KNN SENSITIVITY PLOT - IPAS ONLY
knn_metric_plotter(num_neighbors=50, mean_metric=MeanSenseIPA, best_k=maxSenseIPA,
                   metric_name="Sensitivity", v_offset_multiplier=0.025)


```

```{r echo = FALSE}

# KNN SPECIFICITY PLOT - IPAS ONLY
knn_metric_plotter(num_neighbors=50, mean_metric=MeanSpecIPA, best_k=maxSpecIPA,
                   metric_name="Specificity", v_offset_multiplier=0.005)


```
# Ale Style Beers

```{r echo = FALSE}

# KNN ACCURACY PLOT - ALES ONLY
knn_metric_plotter(num_neighbors=50, mean_metric=MeanAccAle, best_k=maxAccAle,
                   metric_name="Accuracy", v_offset_multiplier=0.015, h_shift=2, beer_style="Ale")

```



```{r echo = FALSE}

# KNN SENSITIVITY PLOT - ALES ONLY
knn_metric_plotter(num_neighbors=50, mean_metric=MeanSenseAle, best_k=maxSenseAle,
                   metric_name="Sensitivity", v_offset_multiplier=0.015, beer_style="Ale")

```



```{r echo = FALSE}

# KNN SPECIFICITY PLOT - ALES ONLY
knn_metric_plotter(num_neighbors=50, mean_metric=MeanSpecAle, best_k=maxSpecAle,
                   metric_name="Specificity", v_offset_multiplier=0.0003, h_shift=1.75, beer_style="Ale")

```
```{r echo = FALSE}

library(dbscan)
library(RcmdrMisc)

#install.packages("dbscan")
#install.packages("RcmdrMisc")

brewery_location_df <- read.csv("./Project1Files/All_Brewery_Location_Data.csv")

#alaska_filter <- brewery_location_df["lat"] > 51 
#hawaii_filter <- brewery_location_df["lat"] < 21 | brewery_location_df["long"] < -140
#continential_df <- brewery_location_df[!alaska_filter & !hawaii_filter,]


#lat_filter <- brewery_location_df["lat"] < 45
#lat_filter2 <- brewery_location_df["lat"] > 42
#long_filter <- brewery_location_df["long"] > -80
#filters <- lat_filter & long_filter & lat_filter2
#test <- continential_df[,c("lat", "long")]
#kmeans_clusters <- KMeans(x=test, centers=3)
#test$cluster <- kmeans_clusters$cluster
#data.frame(kmeans_clusters$centers)
#centers <- kmeans_clusters$centers
#centers_df <- data.frame(centers)
#centers_df["cluster"] <- seq(1, nrow(centers_df), 1)
#centers_df
#test

```





```{r echo = FALSE}


# ====================================================================================
# SET-UP MAP TO USE IN CLUSTER PLOTTING FUNCTIONS
# ====================================================================================

combined_df$State <- trimws(combined_df$State)

state_medians <- combined_df %>% group_by(State) %>% summarize(median_ibu=median(IBU),
                                                               median_abv=median(ABV))

state_medians <- as.data.frame(state_medians)

# Create a dataframe of state abbreviations and state full names.
state_name_lookup <- data.frame(State = state.abb, name=state.name)

states <- map_data("state")

 
state_data <- merge(state_name_lookup, state_medians)

state_data$region <-tolower(state_data$name)

map_plot_data <- merge(states, state_data)

map_plot_data <- map_plot_data[order(map_plot_data$order),]

#
# KMEANS PLOTTING FUNCTION
#
plot_kmeans <- function(brew_df=brewery_location_df, map_plot_df=map_plot_data, num_centroids=4,
                        alpha=0.4, pch=21, fill="black", size=1.5, stroke=2, filter_alaska=TRUE, 
                        filter_hawaii=TRUE, shade_ibu=TRUE, shade_abv=FALSE, plot_cluster_centers=TRUE) 
  {
    kmeans_df <- brew_df[, c("lat", "long")]
    alaksa_filter <- (brew_df["lat"] > 51)
    hawaii_filter <- (brew_df["lat"] < 22)
    
    if(filter_alaska & filter_hawaii){
      kmeans_df <- kmeans_df[!alaksa_filter & !hawaii_filter,]
      
    }else if(filter_hawaii) {
      kmeans_df <- kmeans_df[!hawaii_filter,]
      
    }else if(filter_alaska){
      kmeans_df <- kmeans_df[!alaksa_filter,]
    }
    
      # Shading heatmap backgroup according to the states median IBU is the default
    # However, shade_abv overrides this option without the need to adjust shade_ibu parameter
    
    if(shade_ibu){
      map_plot_df$current_shading <- map_plot_df$median_ibu
      shadeby <- "Median IBU"
    }
    if(shade_abv){
      map_plot_df$current_shading <- map_plot_df$median_abv
      shadeby <- "Median ABV"
    }
  
    kmeans_clusters <- KMeans(x=kmeans_df, centers=num_centroids)
    kmeans_df$cluster <- as.factor(kmeans_clusters$cluster)
    
    # If we want to plot the cluster centers too
    centroids_df <- data.frame(kmeans_clusters$centers)
    centroids_df["cluster"] <- as.factor(seq(1, nrow(centroids_df), 1))

    
    # Plot the heat map, with annotation for the top 5 states.
    kmeans_plot <- ggplot(map_plot_df, aes(x=long, y=lat, group=group)) +
      geom_polygon(aes(fill=current_shading), alpha=alpha) +
      geom_path() +
      scale_fill_gradientn(colours=rev(heat.colors(12)),na.value="grey90") +
      ggtitle(paste0("Brewery Clusters (KMEANS, ",num_centroids, " centroids), States shaded by ", shadeby)) +
      xlab("longitude") + 
      ylab("latitude") +
      coord_map() +
      geom_point(data=kmeans_df, aes(x=long, y=lat, group=NA, color=cluster), pch=pch, fill=fill, size=size, stroke=stroke)
    
    if(plot_cluster_centers){
      
      kmeans_plot <- kmeans_plot + 
        geom_point(data=centroids_df, aes(x=long, y=lat, group=NA, color=cluster), size=6, shape=8, stroke=2)
      
    }
    
    return(kmeans_plot)
  
  }


#
# DBSCAN PLOTTING FUNCTION
#
plot_dbscan <- function(brew_df=brewery_location_df, map_plot_df=map_plot_data, eps=2,
                        alpha=0.4, pch=21, fill="black", size=1.5, stroke=2, minPts=5,
                        filter_alaska=TRUE, filter_hawaii=TRUE, shade_ibu=TRUE, shade_abv=FALSE) {
  
  
  scan_df <- brew_df[, c("lat", "long")]
  alaksa_filter <- (brew_df["lat"] > 51)
  hawaii_filter <- (brew_df["lat"] < 22)
  
  if(filter_alaska & filter_hawaii){
    scan_df <- scan_df[!alaksa_filter & !hawaii_filter,]
    
  }else if(filter_hawaii) {
    scan_df <- scan_df[!hawaii_filter,]
    
  }else if(filter_alaska){
    scan_df <- scan_df[!alaksa_filter,]
  }
  
  # Shading heatmap backgroup according to the states median IBU is the default
  # However, shade_abv overrides this option without the need to adjust shade_ibu parameter
  
  if(shade_ibu){
    map_plot_df$current_shading <- map_plot_df$median_ibu
    shadeby <- "Median IBU"
  }
  if(shade_abv){
    map_plot_df$current_shading <- map_plot_df$median_abv
    shadeby <- "Median ABV"
  }

  
  # Run the DBSCAN
  scan <- dbscan(x=scan_df, eps=eps, minPts=minPts)

  # Store the cluster assignments
  scan_df["cluster_assignment"] <- scan$cluster
  
  # Separate clusters from noise points, so we can have clear markings for each on the map
  noise_df <- scan_df[scan_df["cluster_assignment"] == "0",]
  scan_df <- scan_df[scan_df["cluster_assignment"] != "0",]
  
  scan_df["cluster_assignment"] <- as.factor(scan_df$cluster_assignment)
  
    # Plot the heat map, with annotation for the top 5 states.
  full_plot <- ggplot(map_plot_df, aes(x=long,y=lat, group=group)) +
    geom_polygon(aes(fill=current_shading), alpha=alpha) +
    geom_path() +
    scale_fill_gradientn(colours=rev(heat.colors(12)),na.value="grey90") +
    ggtitle(paste0("Brewery Clusters (DBSCAN EPS=", eps, "), States shaded by ", shadeby)) +
    xlab("longitude") + 
    ylab("latitude") +
    coord_map() +
    geom_point(data=scan_df, aes(x=long, y=lat, group=NA, color=cluster_assignment), pch=pch, fill=fill, size=size, stroke=stroke) +
    geom_point(data=noise_df, aes(x=long, y=lat, group=NA), color="black", shape=4)
  
  return(full_plot)
  
}


```
# KMeans Plotting Section

```{r echo = FALSE, fig.width=10,fig.height=8}

plot_kmeans(num_centroids=3, plot_cluster_centers = FALSE)


```


```{r echo = FALSE, fig.width=10,fig.height=8}

# KMeans with 4 clusters, and without plotting cluster centroids.
plot_kmeans()

```


```{r echo = FALSE, fig.width=10,fig.height=8}

# KMeans with 4 clusters, and without plotting cluster centroids.
plot_kmeans(num_centroids=4, plot_cluster_centers=FALSE)

```


```{r echo = FALSE, fig.width=10,fig.height=8}

# KMeans with 5 clusters.
plot_kmeans(num_centroids=5, plot_cluster_centers=FALSE)

```

```{r echo = FALSE, fig.width=10,fig.height=8}

# KMeans with 5 clusters, shading background with Median ABV instead of Median IBU.
plot_kmeans(num_centroids=5, shade_abv=TRUE)

```


```{r echo = FALSE, fig.width=10,fig.height=8}

# KMeans with 5 clusters, shading background with Median ABV instead of Median IBU.
plot_kmeans(num_centroids=6, shade_abv=TRUE, plot_cluster_centers=FALSE)

```



# DBSCAN Plotting Section

```{r echo = FALSE, fig.width=10,fig.height=8}

# Changing epsilon distance to three and recreating plot above
# EPSILON DISTANCE AT DEFAULT=2

plot_dbscan()

```
```{r echo = FALSE, fig.width=10,fig.height=8}

# Changing epsilon distance to 1
plot_dbscan(eps=2, minPts=4, shade_abv = FALSE)

```

```{r echo = FALSE, fig.width=10,fig.height=8}

# Changing epsilon distance to 1
plot_dbscan(eps=2, minPts=4, shade_abv = TRUE)

```



```{r echo = FALSE, fig.width=10,fig.height=8}

# Changing epsilon distance to 2.5 and shading heat map according to ABV instead of IBU
plot_dbscan(eps=2.5, shade_abv=TRUE)

```



```{r echo = FALSE, fig.width=10,fig.height=8}

# Changing epsilon distance to 3 
plot_dbscan(eps=3)

```



## Question 9: Knock their socks off!  Find one other useful inference from the 
##             data that you feel Budweiser may be able to find value in.  
##             You must convince them why it is important and back up your 
##             conviction with appropriate statistical evidence. 

```{r echo = FALSE}
#find states that are lacking breweries and suggest expansion opportunities.

# Count how many breweries are in each state
breweries_per_state <- brewery_df %>% group_by(State) %>% summarize(count = n())

# Put the data frame in ascending order by num Breweries - Bottom 6 states are DC, ND, SD, WV, AR, DE
head(arrange(breweries_per_state, count))

# States with one or two breweries.
arrange((breweries_per_state %>% filter(count == 1 | count == 2)), count)

# States with one to four breweries - There are 19 states that have four or fewer breweries. Potential expansion opportunities.
arrange((breweries_per_state %>% filter(count == 1 | count == 2 | count == 3 | count == 4)), count)

# It turns out there are only one or two unique instances of each brewery. So this doesn't mean much to us. I thought if there were breweries that occurred several times throughout the US it might have implied popularity.
num_occurences_of_breweries <- brewery_df %>% group_by(Name) %>% summarize(count = n())
arrange(num_occurences_of_breweries, desc(count))

# Extra - Put the data frame in descending order by num Breweries - Top 6 states are CO, CA, MI, OR, TX, PA
head(arrange(breweries_per_state, desc(count)))


# Looking at the states with the most breweries and at the states with the least breweries we are suggesting that if the conditions are right, maybe it would be strategic to start up breweries in the states that have fewer breweries.

```
